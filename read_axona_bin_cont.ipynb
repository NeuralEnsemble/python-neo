{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "distinct-paris",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "Note: This should not be merged into python-neo, but helps me figure out how to write axonarawio.py. I will add it to the axonarawio branch for now, but should delete it before a PR!\n",
    "</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-requirement",
   "metadata": {},
   "source": [
    "# Read axona .bin file\n",
    "\n",
    "We will go through the steps for reading in Axona dacqUSB system .bin data in continuous format.\n",
    "The goal is to later implement this in axonarawio.py.\n",
    "\n",
    "Here is the relevant information from the dacqUSB manual (found here: http://space-memory-navigation.org/DacqUSBFileFormats.pdf):\n",
    "\n",
    "\n",
    "### Header\n",
    "The header consists of:\n",
    "* 4 bytes ID (will be \"ADU1\", unless the tracker position record is populated with valid data,\n",
    "in which case it will be \"ADU2\")\n",
    "* 4 bytes packet number\n",
    "* 2 bytes digital inputs\n",
    "* 2 bytes sync inputs\n",
    "* 20 bytes tracker position record (only valid data if packet ID is \"ADU2\") -- same format as\n",
    "standard .pos file position records.\n",
    "\n",
    "### Data\n",
    "Then there are three samples x 64 channels x 16-bits (= 384 bytes), followed by 16\n",
    "dummy bytes at the end to make up the total packet length of 432. The samples order is\n",
    "given below. Each sample is two bytes long, in 2's complement.\n",
    "The data are stored at 48 kHz, so you should have 16000 packets of 432 bytes per second\n",
    "of recording. Yes, this is very inefficient because you don't have anywhere near 64\n",
    "channels so it is mostly wasted space; this will be improved in a future version update.\n",
    "The main complication is that the order of the channels in the data file is not something\n",
    "nice like 1,2,3, ... Instead, there is a remapping function:\n",
    "<p>\n",
    "remap_channels : array [1..64] of word = (\n",
    " 32, 33, 34, 35, 36, 37, 38, 39,\n",
    " 0, 1, 2, 3, 4, 5, 6, 7,\n",
    " 40, 41, 42, 43, 44, 45, 46, 47,\n",
    " 8, 9, 10, 11, 12, 13, 14, 15,\n",
    " 48, 49, 50, 51, 52, 53, 54, 55,\n",
    " 16, 17, 18, 19, 20, 21, 22, 23,\n",
    " 56, 57, 58, 59, 60, 61, 62, 63,\n",
    " 24, 25, 26, 27, 28, 29, 30, 31 ); \n",
    "</p>\n",
    "\n",
    "For instance, if you want to find the data for channel 7, you look at remap_channels[7],\n",
    "which is 38. So, in the 432-byte packet, you ignore the 32 byte header, and the data for\n",
    "channel 7 will be at:\n",
    "* bytes 32(header)+(38*2), and 32+(38*2+1) (first sample low and high bytes)\n",
    "* bytes 32(header)+128(first samples, 64 ch x 2 bytes)+(38*2), and 32+128+(38*2+1) (2nd sample) \n",
    "* bytes 32+128+128+(38*2), and 32+128+128+(38*2+1) (third sample) and so on.\n",
    "\n",
    "### Trailer\n",
    "Finally, the trailer consists of 16 bytes:\n",
    "2 bytes contain a record of digital output values\n",
    "2 bytes contain stimulator status\n",
    "10 bytes of zeroes (reserved for future use)\n",
    "2 bytes contain the ASCII keycode if a key was pressed during the time the packet was\n",
    "active. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sonic-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import mmap  # python library for memory mapping\n",
    "import numpy as np  # contains np.memmap for memory mapping (used in python-neo)\n",
    "import contextlib  # useful for managing contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educational-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../freelance-work/catalyst-neuro/hussaini-lab-to-nwb/example_data_raw/20201004_Raw.bin\n"
     ]
    }
   ],
   "source": [
    "# Set directory and filename\n",
    "\n",
    "dir_name = r'../../freelance-work/catalyst-neuro/hussaini-lab-to-nwb/example_data_raw'\n",
    "base_filename = '20201004_Raw'\n",
    "suffix = '.bin'\n",
    "\n",
    "bin_file = os.path.join(dir_name, base_filename + suffix)\n",
    "\n",
    "print(bin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indie-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ADU1\\x8d\\x04\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe0\\xeex\\xe88\\xeex\\xccl\\xe2\\x84\\xea\\x1e\\x03J\\t^\\x07l\\xe2<\\xffb\\xfdl\\xef\\xd6\\xee8\\xf1\\\\\\xea\\x8czJ\\xf8\\x9a\\xfa8\\xf1\\xc2\\x1a\\x80\\r\\xc4\\xf0\\xd8\\x06\\x1e\\x15\\xc0\\xf6\\xbc\\x06\\xb0\\x03\\xce\\xfb\\x1e\\x15\\xfa\\xef\\xf6\\rb\\x0e\\xb2\\x06\\xf0(|%\\n\\xed,1\\xbcJ\\xf0(\\xe6\\xfe\"\\x03f\\xf9\\xd8\\x03\\x10\\x140\\x1d\\x02\\x1a\\xb2\\x15\\xa8A\\x10\\x14\\x86\\t\\xe0\\xf7\\x1e\\x07\\xde\\x06x\\xf3\\x0e\\xf4\\xa2\\xa8\\xfc\\xca\\xce\\xedx\\xf3j\\x11\\xa2\\x16\\x16\\x04\\x94\\xe82\\xff\\xfc\\xe8:\\xb1>\\x03v\\xf82\\xff\\xea\\xdb\\xc8\\xe7Z\\xf0\\x9c\\xf0\\xd8\\xfc\\x1a\\xd7\\x0c\\xe6\\x10\\xe9\\x1e\\xd1\\xd8\\xfc\\xba\\xd5\\xb6\\xe3\\x90\\xe7P\\xe0\\x90\\xe7j\\xe9v\\xff\\xae\\xe9p\\xde\\x90\\xe7l\\x12F\\x02\\x84\\x0f\\xe4\\x11\\xce\\x06\\x1a\\xff\\xe2\\xf0D\\xff\\xbc\\x14\\xce\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# Read the first 432 bytes and look at them\n",
    "\n",
    "with open(bin_file, 'rb') as f:\n",
    "    content = f.read(432)\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-biology",
   "metadata": {},
   "source": [
    "Note the substantial amount of wasted space (always assuming 64 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-prompt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ADU1\\x8d\\x04\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xe0\\xeex\\xe88\\xeex\\xccl\\xe2\\x84\\xea\\x1e\\x03J\\t^\\x07l\\xe2<\\xffb\\xfdl\\xef\\xd6\\xee8\\xf1\\\\\\xea\\x8czJ\\xf8\\x9a\\xfa8\\xf1\\xc2\\x1a\\x80\\r\\xc4\\xf0\\xd8\\x06\\x1e\\x15\\xc0\\xf6\\xbc\\x06\\xb0\\x03\\xce\\xfb\\x1e\\x15\\xfa\\xef\\xf6\\rb\\x0e\\xb2\\x06\\xf0(|%\\n\\xed,1\\xbcJ\\xf0(\\xe6\\xfe\"\\x03f\\xf9\\xd8\\x03\\x10\\x140\\x1d\\x02\\x1a\\xb2\\x15\\xa8A\\x10\\x14\\x86\\t\\xe0\\xf7\\x1e\\x07\\xde\\x06x\\xf3\\x0e\\xf4\\xa2\\xa8\\xfc\\xca\\xce\\xedx\\xf3j\\x11\\xa2\\x16\\x16\\x04\\x94\\xe82\\xff\\xfc\\xe8:\\xb1>\\x03v\\xf82\\xff\\xea\\xdb\\xc8\\xe7Z\\xf0\\x9c\\xf0\\xd8\\xfc\\x1a\\xd7\\x0c\\xe6\\x10\\xe9\\x1e\\xd1\\xd8\\xfc\\xba\\xd5\\xb6\\xe3\\x90\\xe7P\\xe0\\x90\\xe7j\\xe9v\\xff\\xae\\xe9p\\xde\\x90\\xe7l\\x12F\\x02\\x84\\x0f\\xe4\\x11\\xce\\x06\\x1a\\xff\\xe2\\xf0D\\xff\\xbc\\x14\\xce\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ADU2\\x8e\\x04\\x00\\x00\\x00\\x00\\x01\\x00x\\x08\\x00\\x000\\x00\\xab\\x00\\xff\\x03\\xff\\x03\\x00\\x00\\n\\x00\\x00\\x00\\n\\x00v\\xf3\\xb0\\xe4,\\xffj\\xe9\\xa4\\xfe\\xfa\\xf6d\\xf2\\xae\\xfa\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00<\\x0c\\\\\\x10H\\xfe\\xd8\\x00\\xd0\\x06.\\x07\\x86\\x02\\xa4\\x04\\xa6\\xfb\\xbc\\xfc\\x8a\\xfd\\x9c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xc4\\xfa\\xfa\\xe3\\xd2\\xee\\x98\\xee\\xb0\\x02*\\xfaf\\xf9\\xf4\\xfb\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x84\\xff\\x98\\rr\\xfd*\\xfc\\x10\\x08\\x16\\x07$\\x07\\x1e\\x00\\x16\\xfbP\\xfcD\\xfd\\xae\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00L\\xff\\x86\\xe2*\\xe1\\x90\\xeeX\\xfdj\\xfb\\xc8\\xf9\\xe0\\xfc\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\xf9X\\n\\x82\\xfa(\\xf7.\\x02d\\x05.\\x08~\\xf7\\x8a\\xfa\\xe6\\xfb\\xfe\\xfc\\xc0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80\\x00\\x80\\x8c\\x00\\x15\\x00^7\\r\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# Read the first 432 * 2 bytes and look at them\n",
    "\n",
    "with open(bin_file, 'rb') as f:\n",
    "    content = f.read(432 * 2)\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-penny",
   "metadata": {},
   "source": [
    "At a glance it seems sensible to use f.read() 432 byte snippet by 432 byte snippet since there is no global header or footer. \n",
    "Note that the pointer moves with every call to f.read(), if I want to reset it to the beginning I could use f.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600100\n"
     ]
    }
   ],
   "source": [
    "# How many 432 byte packets does this data contain (<=> num. samples / 3)?\n",
    "\n",
    "bytes_per_packet = 432\n",
    "\n",
    "with open(bin_file, 'rb') as f:\n",
    "\n",
    "    with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as mmap_obj:\n",
    "        num_packets = int(len(mmap_obj)/bytes_per_packet)\n",
    "        print(num_packets)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vietnamese-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bytes according to mmap_obj: 4147243200\n",
      "Bytes according to Windows OS: 4147243200\n"
     ]
    }
   ],
   "source": [
    "# Windows tells me the .bin file is 4147243200  bytes\n",
    "\n",
    "print('Bytes according to mmap_obj:', num_packets * bytes_per_packet)\n",
    "print('Bytes according to Windows OS:', 4147243200)\n",
    "\n",
    "assert(num_packets * bytes_per_packet == 4147243200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "resistant-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of raw_data: 2073621600\n",
      "Peak at raw_data: [ -4384  -6024  -4552 -13192  -7572  -5500    798   2378   1886  -7572]\n",
      "Type of raw_data: <class 'numpy.memmap'>\n"
     ]
    }
   ],
   "source": [
    "# Try with np.memmap instead - already gives me the data in ndarray, but still memory mapped\n",
    "\n",
    "global_header_size = 0\n",
    "raw_data = np.memmap(bin_file, dtype='int16', mode='r', offset=global_header_size)\n",
    "\n",
    "print('Size of raw_data:', len(raw_data))\n",
    "print('Peak at raw_data:', raw_data[16:26])\n",
    "print('Type of raw_data:', type(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "respiratory-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data with code snippet from BinConverter, using mmap library:\n",
    "# https://github.com/HussainiLab/BinConverter/blob/master/BinConverter/core/readBin.py\n",
    "\n",
    "num_test_samples = num_packets  # read only a few bytes for testing purposes\n",
    "\n",
    "bytes_per_packet = 432\n",
    "bytes_of_data = 384\n",
    "bytes_of_head = 32\n",
    "bytes_of_tail = 16\n",
    "\n",
    "with open(bin_file, 'rb') as f:\n",
    "\n",
    "    with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as mmap_obj:\n",
    "        num_packets = int(len(mmap_obj)/bytes_per_packet)\n",
    "        \n",
    "        data = np.ndarray((num_test_samples,), (np.int16, (1,bytes_of_data//2)),  # replace num_test_samples with num_packets\n",
    "                          mmap_obj[0:bytes_per_packet*num_test_samples],  # ultimately read all\n",
    "                          bytes_of_head, (bytes_per_packet,))  #.reshape((-1, 1)).flatten()\n",
    "        #data = samples_to_array(data, channels=channels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "registered-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-4384 -6024 -4552 ...     0     0     0]]\n",
      "\n",
      " [[-3210 -6992  -212 ...     0     0     0]]\n",
      "\n",
      " [[ 1076 -7874 -8788 ...     0     0     0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4784  3388 10956 ...     0     0     0]]\n",
      "\n",
      " [[-1540  7270 -4724 ...     0     0     0]]\n",
      "\n",
      " [[-8878 -3490 -9256 ...     0     0     0]]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(data[0:10])\n",
    "print(type(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "trained-wisdom",
   "metadata": {},
   "source": [
    "Is there a clear advantage of one over the other? As it is implemented now, np.memmap seems much faster. And we might actually need the np.memmap object rather than a np.ndarray.\n",
    "\n",
    "I think I could use np.memmap and then select only the data I want where necessary, e.g. in `_get_analogsignal_chunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-humor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-journalism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-museum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
